{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch timm opencv-python matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import time\n",
    "import torch\n",
    "import timm\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Initialize the model using PyTorch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select your model type by uncommenting a line from below labeled 'model_type'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one of the following models:\n",
    "#model_type = \"DPT_Large\" # Highest quality model\n",
    "model_type = \"DPT_Hybrid\" # Average quality model\n",
    "#model_type = \"MiDaS_small\" # Lowest quality model\n",
    "\n",
    "#Download the model\n",
    "midas = torch.hub.load('intel-isl/midas', model_type, pretrained=True)\n",
    "\n",
    "#Load the model onto a device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "midas.to(device)\n",
    "midas.eval()\n",
    "\n",
    "#Download transformations\n",
    "midas_transform = torch.hub.load('intel-isl/MiDaS', 'transforms')\n",
    "\n",
    "if model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n",
    "    transform = midas_transform.dpt_transform\n",
    "else:\n",
    "    transform = midas_transform.small_transform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Create Depth Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_depth_map(frame):\n",
    "\n",
    "    # Apply transformations to frame\n",
    "    input_frame_batch = transform(frame).to(device)\n",
    "\n",
    "    # Get predictions from model\n",
    "    with torch.no_grad():\n",
    "        prediction = midas(input_frame_batch)\n",
    "        prediction = torch.nn.functional.interpolate(prediction.unsqueeze(1), size=frame.shape[:2], mode='bicubic', align_corners=False).squeeze()\n",
    "\n",
    "    # Get depth map as numpy array from the gpu to the cpu\n",
    "    depth_map = prediction.cpu().numpy()\n",
    "\n",
    "    #Normalize numpy array into 0-1 range\n",
    "    depth_map = cv.normalize(depth_map, None, 0, 1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
    "\n",
    "    depth_map = (depth_map * 255).astype(np.uint8)\n",
    "    depth_map = cv.applyColorMap(depth_map, cv.COLORMAP_JET)\n",
    "\n",
    "    return depth_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Choose Input Solution For MiDaS model\n",
    "\n",
    "You can choose images, video, or from a camera connected to your computer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webcam Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv.VideoCapture(0)\n",
    "\n",
    "while capture.isOpened():\n",
    "\n",
    "    # Capture frame\n",
    "    status, frame = capture.read()\n",
    "\n",
    "    #Get start time of frame\n",
    "    start = time.time()\n",
    "    \n",
    "    # Get depth map\n",
    "    depth_map = create_depth_map(frame)\n",
    "\n",
    "    #Get end time of frame\n",
    "    end = time.time()\n",
    "\n",
    "    # Get FPS to display\n",
    "    total_time = end - start\n",
    "    fps = 1 / total_time\n",
    "\n",
    "    # Display the webcam frame\n",
    "    cv.putText(frame, \"Press 'Spacebar' to quit\", (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "    cv.putText(frame, f'FPS: {int(fps)}', (20,70), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "    cv.imshow('Webcam', frame)\n",
    "\n",
    "    #Display the depth map for the webcam frame\n",
    "    cv.putText(depth_map, \"Press 'Spacebar' to quit\", (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "    cv.putText(depth_map, f'FPS: {int(fps)}', (20,70), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0))\n",
    "    cv.imshow('Depth Map', depth_map)\n",
    "\n",
    "    # Close the windows on Spacebar\n",
    "    if(cv.waitKey(5) & 0xFF == ord(' ')):\n",
    "        break\n",
    "\n",
    "# Release device and destroy all windows\n",
    "capture.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bcae0c37f40a3d8c10515eeb3adba63de3ea1c9185115b71dc9eb5735684453"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
